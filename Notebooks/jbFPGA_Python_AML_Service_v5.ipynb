{"cells":[{"cell_type":"code","source":["# https://github.com/azure/aml-real-time-ai\n# https://jbfpgaaml-jbarnes1.notebooks.azure.com/j/notebooks/project-brainwave-quickstart.ipynb\n# Deploy models with the Azure Machine Learning service\n# https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where#choose-a-compute-target\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# ---------------------------------------------------------------------------------------\n# Set Azure Subscription Parms\n# ---------------------------------------------------------------------------------------\n#!az login\n!Connect-AzAccount\n!Select-AzSubscription -Subscription \"82d7b191-5a8c-4cbf-a9f9-9aa5fb50feaa\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# -----------------------------------------------------------------------\n# SET-UP workSpace Parms\n# -----------------------------------------------------------------------\nimport os\nimport tensorflow as tf\nsubscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"82d7b191-5a8c-4cbf-a9f9-9aa5fb50feaa\")\nresource_group = os.getenv(\"RESOURCE_GROUP\", default=\"jbfpga\")\nworkspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"jbfpgamlws\")\nworkspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# -----------------------------------------------------------------------\n# WRITE (Optional) WorkSpace Parms\n# -----------------------------------------------------------------------\nfrom azureml.core import Workspace\n\ntry:\n    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n    # write the details of the workspace to a configuration file to the notebook library\n    ws.write_config()\n    print(\"Workspace configuration succeeded.\")\nexcept:\n    print(\"Workspace not accessible.\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Workspace configuration succeeded.\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# -----------------------------------\n# Retrieve Workspace\n# -----------------------------------\nfrom azureml.core import Workspace\n\nws = Workspace.from_config()\nprint(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">jbfpgamlws\njbfpga\neastus2\n82d7b191-5a8c-4cbf-a9f9-9aa5fb50feaa\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# ------------------------------\n# Input images as a two-dimensional tensor containing an arbitrary number of images represented a strings\n# ------------------------------\nimport azureml.accel.models.utils as utils\ntf.reset_default_graph()\n\nin_images = tf.placeholder(tf.string)\nimage_tensors = utils.preprocess_array(in_images)\nprint(image_tensors.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(?, 224, 224, 3)\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# ------------------------------\n# Featurizer\n# ------------------------------\n#We use ResNet50 as a featurizer. In this step we initialize the model. This downloads a TensorFlow checkpoint of the quantized ResNet50.\nfrom azureml.accel.models import QuantizedResnet50\nsave_path = os.path.expanduser('~/models')\nmodel_graph = QuantizedResnet50(save_path, is_frozen = True)\nfeature_tensor = model_graph.import_graph_def(image_tensors)\nprint(model_graph.version)\nprint(feature_tensor.name)\nprint(feature_tensor.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1.1.2\nbrainwave_target_node_1_Version_0.1:0\n(?, 1, 1, 2048)\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# ------------------------------\n# Classifier\n# ------------------------------\n#The model we downloaded includes a classifier which takes the output of the ResNet50 and identifies an image. This classifier is trained on the ImageNet dataset. We are going to use this classifier for our service. The next #notebook shows how to train a classifier for a different data set. The input to the classifier is a tensor matching the output of our ResNet50 featurizer.\nclassifier_output = model_graph.get_default_classifier(feature_tensor)\nprint(classifier_output)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Tensor(&quot;classifier/resnet_v1_50/predictions/Softmax:0&quot;, shape=(?, 1000), dtype=float32)\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# ---------------------------------------\n# SAVE Model\n# model_name must be lowercase\n# ---------------------------------------\n\n#save_path = os.path.expanduser('~/models/save/')\nsave_path = \"/databricks/driver/\"\n\nmodel_name = \"resnet50-3\"\nmodel_save_path = os.path.join(save_path, model_name)\nprint(\"Saving model in {}\".format(model_save_path))\n\nwith tf.Session() as sess:\n    model_graph.restore_weights(sess)\n    tf.saved_model.simple_save(sess, model_save_path,\n                                   inputs={'images': in_images},\n                                   outputs={'output_alias': classifier_output})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Saving model in /databricks/driver/resnet50-3\nINFO:tensorflow:Restoring parameters from /root/models/msfprn50/1.1.2/resnet50_bw\nINFO:tensorflow:Assets added to graph.\nINFO:tensorflow:No assets to write.\nINFO:tensorflow:SavedModel written to: /databricks/driver/resnet50-3/saved_model.pb\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["#!pip install --upgrade tensorflow==2.0.0-beta1\n#!pip install h5py\nimport h5py\n#h5py.run_tests()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#loaded = tf.saved_model.load(\"/databricks/driver/resnet50.8/\")\n\nloaded = tf.keras.models.load_model(\"/databricks/driver/resnet50-2/\")\n\nprint(list(loaded.signatures.keys()))  # [\"serving_default\"]"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# -----------------------------------\n# Important! Save names of input and output tensors\n# -----------------------------------\ninput_tensors = in_images.name\noutput_tensors = classifier_output.name\n\nprint(input_tensors)\nprint(output_tensors)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Placeholder:0\nclassifier/resnet_v1_50/predictions/Softmax:0\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# ----------------------------------\n# REGISTER MODEL\n# ----------------------------------\nsave_path =  os.path.expanduser(\"\")\nmodel_name = \"resnet50-3\"\nmodel_save_path = os.path.join(save_path, model_name)\n\n\nfrom azureml.core.model import Model\n\nregistered_model = Model.register(workspace = ws,\n                                  model_path = model_save_path,\n                                  model_name = model_name)\n\nprint(\"Successfully registered: \", registered_model.name, registered_model.description, registered_model.version, sep = '\\t')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Registering model resnet50-3\nSuccessfully registered: \tresnet50-3\tNone\t1\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# ----------------------------------\n# CONVERT MODEL\n# Note: Conversion may take a while and on average for FPGA model it is about 1-3 minutes and it depends on model type\n# ----------------------------------\nfrom azureml.accel import AccelOnnxConverter\n\nconvert_request = AccelOnnxConverter.convert_tf_model(ws, registered_model, input_tensors, output_tensors)\n# If it fails, you can run wait_for_completion again with show_output=True. False\nconvert_request.wait_for_completion(show_output = True)\n# If the above call succeeded, get the converted model\nconverted_model = convert_request.result\nprint(\"\\nSuccessfully converted: \", converted_model.name, converted_model.url, converted_model.version, \n      converted_model.id, converted_model.created_time, '\\n')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Running.........................\nSucceeded\nOperation bcb6993c-93a1-4378-b106-438cfa09cd6d completed, operation state &quot;Succeeded&quot;\nsas url to download model conversion logs https://jbfpgamlws2385341934.blob.core.windows.net/azureml/LocalUpload/0977903ff8374324b924a12382ad9efd/conversion_log?sv=2018-03-28&amp;sr=b&amp;sig=3UDcd3tIku3bD8C63dA2U0cdclNnnA%2F7ZAnZZ9%2BoTkE%3D&amp;st=2019-07-02T20%3A42%3A44Z&amp;se=2019-07-03T04%3A52%3A44Z&amp;sp=r\n[2019-07-02 20:50:37Z]: Starting model conversion process\r\n[2019-07-02 20:50:37Z]: Downloading model for conversion\r\n[2019-07-02 20:50:42Z]: Converting model\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,978 [INFO ]  Parsing conversion options\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,978 [DEBUG]  Options: {&apos;toolVersion&apos;: &apos;1.0&apos;, &apos;toolName&apos;: &apos;fpga&apos;, &apos;input_node_names&apos;: &apos;Placeholder:0&apos;, &apos;output_node_names&apos;: &apos;classifier/resnet_v1_50/predictions/Softmax:0&apos;, &apos;require_fpga_conversion&apos;: &apos;True&apos;, &apos;sourceModelFlavor&apos;: &apos;tf&apos;, &apos;targetModelFlavor&apos;: &apos;accelonnx&apos;, &apos;unpack&apos;: &apos;true&apos;}\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,978 [INFO ]  Begin splitting graph ...\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,978 [INFO ]  input path =&gt; /tmp/3iom51tp.gk3/input\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,979 [INFO ]  output path =&gt; /tmp/tmppi_ev_nq\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,979 [INFO ]  Splitting requires FPGA only\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,979 [DEBUG]  Descending into /tmp/3iom51tp.gk3/input/resnet50-3\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,979 [INFO ]  Found model dir /tmp/3iom51tp.gk3/input/resnet50-3\r\n[2019-07-02 20:50:44Z]: converter std: 2019-07-02 20:50:44,979 [INFO ]  Trying to load input directory with SavedModelLoader\r\n[2019-07-02 20:50:44Z]: converter err: 2019-07-02 20:50:44.996993: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n[2019-07-02 20:50:49Z]: converter std: 2019-07-02 20:50:49,494 [INFO ]  Restoring parameters from /tmp/3iom51tp.gk3/input/resnet50-3/variables/variables\r\n[2019-07-02 20:50:49Z]: converter err: /usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\r\n[2019-07-02 20:50:49Z]: converter err:   from ._conv import register_converters as _register_converters\r\n[2019-07-02 20:50:49Z]: converter err: INFO:tensorflow:Restoring parameters from /tmp/3iom51tp.gk3/input/resnet50-3/variables/variables\r\n[2019-07-02 20:50:51Z]: converter std: 2019-07-02 20:50:51,453 [INFO ]  Attempt splitting into ONNX FPGA Graph\r\n[2019-07-02 20:50:51Z]: converter std: 2019-07-02 20:50:51,454 [INFO ]  Splitting into 3 stage pipeline\r\n[2019-07-02 20:50:51Z]: converter std: 2019-07-02 20:50:51,484 [INFO ]  Found brainwave model of type BrainwaveModel.Resnet50\r\n[2019-07-02 20:50:52Z]: converter std: 2019-07-02 20:50:52,301 [INFO ]  Adding stage TensorFlow Placeholder:0 --&gt; brainwave_resnet50_1_Version_0.1_input_1\r\n[2019-07-02 20:50:52Z]: converter std: 2019-07-02 20:50:52,302 [INFO ]  Adding stage Brainwave brainwave_resnet50_1_Version_0.1_input_1 --&gt; brainwave_resnet50_1_Version_0.1_output_1\r\n[2019-07-02 20:50:52Z]: converter std: 2019-07-02 20:50:52,302 [INFO ]  Adding stage TensorFlow brainwave_resnet50_1_Version_0.1_output_1 --&gt; classifier/resnet_v1_50/predictions/Softmax:0\r\n[2019-07-02 20:50:52Z]: converter err: INFO:tensorflow:Froze 0 variables.\r\n[2019-07-02 20:50:52Z]: converter std: 2019-07-02 20:50:52,762 [INFO ]  Froze 0 variables.\r\n[2019-07-02 20:50:53Z]: converter err: 2019-07-02 20:50:53.160870: W tensorflow/core/graph/graph_constructor.cc:1265] Importing a graph with a lower producer version 24 into an existing graph with producer version 27. Shape inference will have run different parts of the graph with different producer versions.\r\n[2019-07-02 20:50:53Z]: converter std: Converted 0 variables to const ops.\r\n[2019-07-02 20:50:53Z]: converter std: 2019-07-02 20:50:53,963 [INFO ]  There are 265 variable names in original BW graph\r\n[2019-07-02 20:50:53Z]: converter std: 2019-07-02 20:50:53,965 [INFO ]  Found 265 matching variables in existing session\r\n[2019-07-02 20:50:57Z]: converter err: INFO:tensorflow:Restoring parameters from /tmp/tmppi_ev_nq/bw_checkpoints/resnet50\r\n[2019-07-02 20:50:57Z]: converter std: 2019-07-02 20:50:57,927 [INFO ]  Restoring parameters from /tmp/tmppi_ev_nq/bw_checkpoints/resnet50\r\n[2019-07-02 20:50:59Z]: converter err: INFO:tensorflow:Froze 265 variables.\r\n[2019-07-02 20:50:59Z]: converter std: 2019-07-02 20:50:59,121 [INFO ]  Froze 265 variables.\r\n[2019-07-02 20:50:59Z]: converter std: Converted 265 variables to const ops.\r\n[2019-07-02 20:50:59Z]: converter err: INFO:tensorflow:Froze 0 variables.\r\n[2019-07-02 20:50:59Z]: converter std: 2019-07-02 20:50:59,927 [INFO ]  Froze 0 variables.\r\n[2019-07-02 20:51:00Z]: converter std: Converted 0 variables to const ops.\r\n[2019-07-02 20:51:00Z]: converter std: 2019-07-02 20:51:00,121 [INFO ]  Parse manifest file generated by splitter\r\n[2019-07-02 20:51:00Z]: converter std: 2019-07-02 20:51:00,122 [INFO ]  Processing tensorflow stage\r\n[2019-07-02 20:51:00Z]: converter std: 2019-07-02 20:51:00,123 [INFO ]  Processing brainwave stage\r\n[2019-07-02 20:51:00Z]: converter std: 2019-07-02 20:51:00,123 [INFO ]  Invoking python3 /converter/external/brainwave/tensorflow_params_to_caffe.py -n ResNet-50 -c /data/models/resnet50/model.prototxt -t /tmp/tmppi_ev_nq/bw_checkpoints/resnet50 -o /tmp/tmpij_jg3m7/model_caffe.out\r\n[2019-07-02 20:51:13Z]: converter std: 2019-07-02 20:51:13,184 [INFO ]  Brainwave compiler output:\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:02.681483] Execution started.\r\n[2019-07-02 20:51:13Z]: converter std: 2019-07-02 20:51:02.739664: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:02.745450] Importing tensorflow graph... Done.\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:07.182682] Restoring variables... Done.\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:08.088776] Converting to Caffe... Done.\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:11.984437] Serializing protocol buffer output... Done.\r\n[2019-07-02 20:51:13Z]: converter std: [2019-07-02 20:51:12.594519] Execution finished. Execution took 9.913019 seconds\r\n[2019-07-02 20:51:13Z]: converter std: /usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\r\n[2019-07-02 20:51:13Z]: converter std:   from ._conv import register_converters as _register_converters\r\n[2019-07-02 20:51:13Z]: converter std: 2019-07-02 20:51:13,185 [INFO ]  Invoking python3 /converter/external/brainwave/generate_firmware.py --output_format=code -i /data/models/resnet50/model.prototxt -mp /tmp/tmpij_jg3m7/model_caffe.out -if /tmp/tmpij_jg3m7/subgraph.graphir -o /tmp/tmpij_jg3m7/firmware.c -off --v3_isa --double_buffer_parameters --back_propagate_strides --prefetch_matrices --merge_layers --disable_agregation_after_layer res2a_branch2a --use_expander --merge_spatial_pool --spatial_pool_interleave=11 --super_prefetch_MRF --super_prefetch_MRF_lookahead=2 --allow_interleaved_output\r\n[2019-07-02 20:52:18Z]: converter std: 2019-07-02 20:52:18,203 [INFO ]  Brainslice firmware generator output:\r\n[2019-07-02 20:52:18Z]: converter std: error:\r\n[2019-07-02 20:52:18Z]: converter std: 2019-07-02 20:52:15.385803: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n[2019-07-02 20:52:18Z]: converter std: /converter/external/brainwave/output_printer.py:4200: SyntaxWarning: assertion is always true, perhaps remove parentheses?\r\n[2019-07-02 20:52:18Z]: converter std:   assert(len(sp)==2, &quot;Shape is expected as 2D&quot;)\r\n[2019-07-02 20:52:18Z]: converter std: /converter/external/brainwave/output_printer.py:4222: SyntaxWarning: assertion is always true, perhaps remove parentheses?\r\n[2019-07-02 20:52:18Z]: converter std:   assert(len(sp)==1, &quot;Shape is expected as 1D&quot;)\r\n[2019-07-02 20:52:18Z]: converter std: /converter/external/brainwave/output_printer.py:4284: SyntaxWarning: assertion is always true, perhaps remove parentheses?\r\n[2019-07-02 20:52:18Z]: converter std:   assert(len(outputVal[1])==1, &quot;Shape is expected as 1D&quot;)\r\n[2019-07-02 20:52:18Z]: converter std: /usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\r\n[2019-07-02 20:52:18Z]: converter std:   from ._conv import register_converters as _register_converters\r\n[2019-07-02 20:52:18Z]: converter std: 2019-07-02 20:52:18,204 [INFO ]  Invoking python3 /converter/external/tf2onnx/tf2onnx/convert.py --input /tmp/tmppi_ev_nq/bw_checkpoints/resnet50.frozen.pb --inputs brainwave_resnet50_1_Version_0.1_input_1:0 --output /tmp/tmpij_jg3m7/resnet50.onnx --outputs brainwave_resnet50_1_Version_0.1_output_1:0 --continue_on_error --custom-rewriter BrainSlice --rewriter-config /data/models/resnet50/converter.json --weight-path /tmp/tmpij_jg3m7 --firmware-path /data/firmware/brainslice-v3-3.0.4/resnet50\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,456 [INFO ]  Onnx converter output:\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:20.314456: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fold_batch_norms\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:20.443367: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fold_old_batch_norms\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:21.218508: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n[2019-07-02 20:52:22Z]: converter std: /usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\r\n[2019-07-02 20:52:22Z]: converter std:   from ._conv import register_converters as _register_converters\r\n[2019-07-02 20:52:22Z]: converter std: /usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\r\n[2019-07-02 20:52:22Z]: converter std:   return _compile(pattern, flags).split(string, maxsplit)\r\n[2019-07-02 20:52:22Z]: converter std: INFO:tf2onnx.optimizer.transpose_optimizer: 0 transpose op(s) left, ops diff after transpose optimization: Counter({&apos;Const&apos;: 0, &apos;Placeholder&apos;: 0, &apos;Pad&apos;: 0, &apos;BrainSlice&apos;: 0, &apos;ReduceMean&apos;: 0, &apos;Identity&apos;: 0})\r\n[2019-07-02 20:52:22Z]: converter std: using tensorflow=1.12.0, onnx=1.3.0, opset=7, tfonnx=0.4.0.fork/6bf11d\r\n[2019-07-02 20:52:22Z]: converter std: Complete successfully, the onnx model is generated at /tmp/tmpij_jg3m7/resnet50.onnx\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,456 [INFO ]  Moving /tmp/tmpij_jg3m7/resnet50.onnx ==&gt; /tmp/3iom51tp.gk3/output/resnet50.onnx\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,596 [INFO ]  Renaming the file /tmp/3iom51tp.gk3/output/Nicholas_Peak_BrainSlice3.cab ==&gt; /tmp/3iom51tp.gk3/output/brainwave.cab\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,596 [INFO ]  Processing tensorflow stage\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,634 [INFO ]  Saving conversion status\r\n[2019-07-02 20:52:22Z]: converter std: 2019-07-02 20:52:22,634 [INFO ]  Conversion completed\r\n[2019-07-02 20:52:23Z]: Uploading conversion results\r\n[2019-07-02 20:52:32Z]: Conversion completed with result Success\r\n\nSuccessfully converted:  resnet50-3.1.accelonnx aml://asset/e9e167ca6a7a49b39822a3af6872cbff 1 resnet50-3.1.accelonnx:1 2019-07-02 20:52:39.186384+00:00 \n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["# ----------------------------------\n# PACKAGE MODEL into an IMAGE\n# \n# ----------------------------------\nfrom azureml.core.image import Image\nfrom azureml.accel import AccelContainerImage\n\nimage_config = AccelContainerImage.image_configuration()\n# Image name must be lowercase\nimage_name = \"{}-image\".format(model_name)\n\nimage = Image.create(name = image_name,\n                     models = [converted_model],\n                     image_config = image_config, \n                     workspace = ws)\nimage.wait_for_creation(show_output = False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating image\n\nImage creation operation finished for image resnet50-3-image:1, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["# ----------------------------------\n# PROVISION -> Azure Kubernetes Service (AKS) Cluster using Azure ML Service\n# Create AKS ComputeTarget -> StandardPB6s (FPGA-Enabled) - Need Special Access!!!\n# This can take awhile!!!\n# ----------------------------------\nfrom azureml.core.compute import AksCompute, ComputeTarget\n\n# Uses the specific FPGA enabled VM (sku: Standard_PB6s)\n# Standard_PB6s are available in: eastus, westus2, westeurope, southeastasia\n# (old) Standard_D3_v2\n# If you are not able to deploy, please fill out a request form \n# with your subscription ID and region you want to deploy to: https://aka.ms/accelerateAI\n\nprov_config = AksCompute.provisioning_configuration(vm_size = \"Standard_PB6s\",\n                                                    agent_count = 1, \n                                                    location = \"eastus\")\n\naks_name = 'JB-FPGA-aks-pb6'\n# Create the cluster\naks_target = ComputeTarget.create(workspace = ws, \n                                  name = aks_name, \n                                  provisioning_configuration = prov_config)\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating......................................................................................................................................................\nSucceededProvisioning operation finished, operation &quot;Succeeded&quot;\nSucceeded\nNone\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# -------------------------------------------------------\n# DEPLOY -  AccelContainerImage to AKS ComputeTarget\n# -------------------------------------------------------\nfrom azureml.core.webservice import Webservice, AksWebservice\n\n#Set the web service configuration (for creating a test service, we don't want autoscale enabled)\n# Authentication is enabled by default, but for testing we specify False\naks_config = AksWebservice.deploy_configuration(autoscale_enabled=False,\n                                                num_replicas=1,\n                                                auth_enabled = False)\n\naks_service_name ='jb-fpga-aks-service-3'\n\naks_service = Webservice.deploy_from_image(workspace = ws,\n                                           name = aks_service_name,\n                                           image = image,\n                                           deployment_config = aks_config,\n                                           deployment_target = aks_target)\naks_service.wait_for_deployment(show_output = True)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Creating service\nRunning...................................\nSucceededAKS service creation operation finished, operation &quot;Succeeded&quot;\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# Get AML WebService IP and Port by Name\nfrom azureml.core.webservice import Webservice\nservice = Webservice(workspace=ws, name='jb-fpga-aks-service-3')\nprint(service.scoring_uri)\nprint(service.name)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">http://40.117.228.157/\njb-fpga-aks-service-3\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["!pip install --upgrade azureml-accel-client"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Using the grpc client in Azure ML Accelerated Models SDK package\nfrom azureml.accel import PredictionClient\n\naddress = aks_service.scoring_uri\nssl_enabled = address.startswith(\"https\")\naddress = address[address.find('/')+2:].strip('/')\nport = 443 if ssl_enabled else 80\n\n# Initialize AzureML Accelerated Models client\nclient = PredictionClient(address=address,\n                          port=port,\n                          use_ssl=ssl_enabled,\n                          service_name=aks_service.name)\nprint(address)\nprint(aks_service.name)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">40.117.228.157\njb-fpga-aks-service-3\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["import requests\nclasses_entries = requests.get(\"https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\").text.splitlines()\n\nfrom azure.storage.blob import BlockBlobService\nblock_blob_service = BlockBlobService(account_name='jbadbsa', account_key='0ofZa0xn0kJ98oE/hZINE9/oKFvLWbaTtD+mbAqHnIDMfZ/ml/j+Wwq9iVIJUBks6IUjSvUqZ/gXvk6tCavlXw==')\n#block_blob_service.get_blob_to_path('images', 'Snowleopard.jpg', 'TestImage.jpg')\nblock_blob_service.get_blob_to_path('images', 'Unicycle.jpg', 'TestImage.jpg')\n#block_blob_service.get_blob_to_path('images', 'PirateShip.jpg', 'TestImage.jpg')\n\nprint(service.scoring_uri)\n# primary, secondary = service.get_keys()\n#print(primary)\n#print(secondary)\n\n#service = Webservice(workspace=ws, name='imagenet-infer')\nprint(service.scoring_uri)\n\n# Score image with input and output tensor names\nresults = client.score_file(path=\"TestImage.jpg\", \n                             input_name=input_tensors, \n                             outputs=output_tensors)\n\nprint(input_tensors)\nprint(output_tensors)\n\n# map results [class_id] => [confidence]\nresults = enumerate(results)\n# sort results by confidence\nsorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n# print top 5 results\nfor top in sorted_results[:5]:\n    print(classes_entries[top[0]], 'confidence:', top[1])\n    \nprint(service)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">http://40.117.228.157/\nhttp://40.117.228.157/\nPlaceholder:0\nclassifier/resnet_v1_50/predictions/Softmax:0\nunicycle, monocycle confidence: 0.9999901\nbicycle-built-for-two, tandem bicycle, tandem confidence: 5.292813e-06\nmountain bike, all-terrain bike, off-roader confidence: 2.821423e-06\ntricycle, trike, velocipede confidence: 1.7468099e-06\nspotlight, spot confidence: 3.0475654e-08\nAksWebservice(workspace=Workspace.create(name=&apos;jbfpgamlws&apos;, subscription_id=&apos;82d7b191-5a8c-4cbf-a9f9-9aa5fb50feaa&apos;, resource_group=&apos;jbfpga&apos;), name=jb-fpga-aks-service-3, image_id=resnet50-3-image:1, compute_type=AKS, state=Healthy, scoring_uri=http://40.117.228.157/, tags={}, properties={})\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["# ------------------------------\n# DELETE Resources (must be done in this order)\n# ------------------------------\n#aks_service.delete()\n#aks_target.delete()\n#image.delete()\n#registered_model.delete()\n#converted_model.delete()\n\n"],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"jbfpga_1","notebookId":1963397126938788},"nbformat":4,"nbformat_minor":0}
